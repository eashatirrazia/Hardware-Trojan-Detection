{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/easha/FYP/hw2vec/examples\n"
     ]
    }
   ],
   "source": [
    "cd /home/easha/FYP/hw2vec/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python use_case_1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the saved graph\n",
    "# graph_path = \"../hardware_graph.pkl\"\n",
    "# with open(graph_path, \"rb\") as f:\n",
    "#     hardware_nxgraph = pickle.load(f)\n",
    "\n",
    "# # Visualize the graph\n",
    "# def visualize_graph(graph):\n",
    "#     pos = nx.spring_layout(graph)\n",
    "#     plt.figure(figsize=(12, 12))\n",
    "#     nx.draw(graph, pos, with_labels=True, node_color='skyblue', node_size=2000, edge_color='gray', font_size=10, font_weight='bold')\n",
    "#     plt.show()\n",
    "\n",
    "# visualize_graph(hardware_nxgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python use_case_2.py --yaml_path ./example_gnn4tj.yaml --raw_dataset_path ../assets/datasets/TJ-RTL-toy --data_pkl_path dfg_tj_rtl.pkl --model_path ../examples  --graph_type DFG --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.listdir(os.getcwd()))\n",
    "\n",
    "# os.getcwd()\n",
    "\n",
    "# os.path.dirname(os.getcwd())\n",
    "\n",
    "# sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# sys.path\n",
    "# os.path.dirname(sys.path[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# sys.path.append(os.path.dirname(sys.path[0]))\n",
    "from hw2vec.hw2vec.config import Config\n",
    "from hw2vec.hw2vec.hw2graph import *\n",
    "from hw2vec.hw2vec.graph2vec.models import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/easha/FYP/iscas/ISCAS89/test3/topModule.v , 51282 , 63450 , 22.4622962474823\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_trained.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m model_path \u001b[38;5;241m=\u001b[39m Path(model_path)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.cfg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_trained.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference\u001b[39m(model, data_loader, config):\n",
      "File \u001b[0;32m/home/easha/FYP/hw2vec/hw2vec/graph2vec/models.py:130\u001b[0m, in \u001b[0;36mGRAPH2VEC.load_model\u001b[0;34m(self, model_config_path, model_weight_path)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# print(fc_in_channel, fc_out_channel)\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_output_layer(nn\u001b[38;5;241m.\u001b[39mLinear(fc_in_channel, fc_out_channel))\n\u001b[0;32m--> 130\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_weight_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m new_state_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Create a mapping from the old key names in the pre-trained model to the new key names in the architecture\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/hw2vec/lib/python3.8/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/hw2vec/lib/python3.8/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/hw2vec/lib/python3.8/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_trained.pth'"
     ]
    }
   ],
   "source": [
    "from hw2vec.hw2vec.config import Config\n",
    "from hw2vec.hw2vec.hw2graph import *\n",
    "from hw2vec.hw2vec.graph2vec.models import *\n",
    "import yaml\n",
    "# Define a class to encapsulate the configuration dictionary\n",
    "class Config:\n",
    "    def __init__(self, config_dict):\n",
    "        self.__dict__.update(config_dict)\n",
    "\n",
    "# Configuration parameters\n",
    "yaml_path = 'hw2vec/examples/example_gnn4tj.yaml'\n",
    "# raw_dataset_path = Path('../assets/testing')\n",
    "# raw_dataset_path = Path('../../AES-T100/src/TjIn') \n",
    "# raw_dataset_path = Path('../../RS232-T100/src/') \n",
    "# raw_dataset_path = Path('../../PIC16F84-T200/src/TjIn') \n",
    "# raw_dataset_path = Path('../../b15-T100/src/TjIn') \n",
    "# raw_dataset_path = Path('../../s15850-T100/src/TjIn') \n",
    "# raw_dataset_path = Path('../../ISCAS85/test2') \n",
    "\n",
    "raw_dataset_path = Path('/home/easha/FYP/iscas/ISCAS89/test3') \n",
    "\n",
    "# verilog_file_path = Path('../../test2') \n",
    "verilog_file_path = raw_dataset_path\n",
    "\n",
    "# raw_dataset_path = Path('../../VerilogTest') \n",
    "\n",
    "data_pkl_path = Path('testing.pkl')\n",
    "graph_type = 'DFG'\n",
    "device = 'cuda'\n",
    "\n",
    "with open(yaml_path, 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Update config_dict with additional parameters\n",
    "config_dict.update({\n",
    "    'raw_dataset_path': str(raw_dataset_path),\n",
    "    'data_pkl_path': str(data_pkl_path),\n",
    "    'graph_type': graph_type,\n",
    "    'device': device\n",
    "})\n",
    "\n",
    "# Initialize the configuration class\n",
    "config = Config(config_dict)\n",
    "\n",
    "# verilog_file_path = Path('../assets/testing') \n",
    "\n",
    "# verilog_file_path = Path('../../AES-T100/src/TjIn')\n",
    "# verilog_file_path = Path('../../RS232-T100/src/')  \n",
    "# verilog_file_path = Path('../../PIC16F84-T200/src/TjIn')  \n",
    "# verilog_file_path = Path('../../b15-T100/src/TjIn')  \n",
    "# verilog_file_path = Path('../../s15850-T100/src/TjIn')  \n",
    "# verilog_file_path = Path('../../ISCAS85/test2')  \n",
    "\n",
    "# verilog_file_path = Path('../../S-seriesprocessed/S-series/TjIn/s15850-T100') \n",
    "\n",
    "# verilog_file_path = Path('../../VerilogTest') \n",
    "\n",
    "nx_graphs = []\n",
    "hw2graph = HW2GRAPH(config)\n",
    "\n",
    "# Process the single Verilog file\n",
    "hw_graph = hw2graph.code2graph(verilog_file_path)\n",
    "nx_graphs.append(hw_graph)\n",
    "\n",
    "data_proc = DataProcessor(config)\n",
    "for hw_graph in nx_graphs:\n",
    "    data_proc.process(hw_graph)\n",
    "data_proc.cache_graph_data(config.data_pkl_path)\n",
    "data=data_proc.get_graphs()\n",
    "\n",
    "# model_path = \"model_trained.pth\"\n",
    "model_path = \"/home/easha/FYP/hw2vec/assets/pretrained_DFG_TJ_RTL/model.pth\"\n",
    "\n",
    "# config_path =  \"model_trained.cfg\"\n",
    "config_path = \"/home/easha/FYP/hw2vec/assets/pretrained_DFG_TJ_RTL/model.cfg\"\n",
    "\n",
    "model = GRAPH2VEC(config)\n",
    "model_path = Path(model_path)\n",
    "if model_path.exists():\n",
    "    model.load_model(config_path, model_path)\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "def inference(model, data_loader, config):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(data_loader):\n",
    "            data = data.to(config.device)  # Move data to the correct device\n",
    "\n",
    "            output, attn = model.embed_graph(data.x, data.edge_index, data.batch)\n",
    "            output = model.mlp(output)\n",
    "            output = F.log_softmax(output, dim=1)\n",
    "            # print(output)\n",
    "            \n",
    "\n",
    "\n",
    "        # outputs = torch.cat(output).reshape(-1, 2).detach()\n",
    "\n",
    "        \n",
    "\n",
    "        # labels_tensor = torch.LongTensor(labels).detach()\n",
    "        outputs_tensor = torch.FloatTensor(output.cpu()).detach()\n",
    "        preds = outputs_tensor.max(1)[1].detach()\n",
    "\n",
    "    return outputs_tensor, preds\n",
    "\n",
    "train_loader = DataLoader(data, shuffle=True, batch_size=1)\n",
    "\n",
    "outputs_tensor, preds=inference(model, train_loader, config)\n",
    "\n",
    "print(f\"The output tensor is: {outputs_tensor}\")\n",
    "print(f\"The predicted class is: {'TJ Free' if preds[0] == 0 else 'TJ Detected'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/easha/FYP/S-seriesfinal/S-series/TjFree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m total_tj_free_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     39\u001b[0m total_tj_detected_in_tj_free_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtj_free_data_dir_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# check if folder is a directory\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tj_free_data_dir_path, folder)):\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/easha/FYP/S-seriesfinal/S-series/TjFree'"
     ]
    }
   ],
   "source": [
    "# import os, sys\n",
    "# # sys.path.append(os.path.dirname(sys.path[0]))\n",
    "# from hw2vec.hw2vec.config import Config\n",
    "# from hw2vec.hw2vec.hw2graph import *\n",
    "# from hw2vec.hw2vec.graph2vec.models import *\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import yaml\n",
    "# from pathlib import Path\n",
    "# import torch.nn.functional as F\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define a class to encapsulate the configuration dictionary\n",
    "# class Config:\n",
    "#     def __init__(self, config_dict):\n",
    "#         self.__dict__.update(config_dict)\n",
    "\n",
    "# # Configuration parameters\n",
    "# yaml_path = 'yaml_files/example_gnn4tj.yaml'\n",
    "# # raw_dataset_path = Path('../assets/testing')\n",
    "# # raw_dataset_path = Path('../../AES-T100/src/TjIn')\n",
    "# # raw_dataset_path = Path('../../RS232-T100/src/')\n",
    "# # raw_dataset_path = Path('../../PIC16F84-T200/src/TjIn')\n",
    "# # raw_dataset_path = Path('../../b15-T100/src/TjIn')\n",
    "# # raw_dataset_path = Path('../../s15850-T100/src/TjIn')\n",
    "# # raw_dataset_path = Path('../../ISCAS85/test2')\n",
    "\n",
    "# # tj_free_data_dir_path = Path('../../S-seriesprocessed/S-series/TjFree')\n",
    "# # base_data_path = Path('../../TJ-RTL-toy-rand-2-test')\n",
    "# base_data_path = Path('/home/easha/FYP/S-seriesfinal/S-series')\n",
    "\n",
    "\n",
    "# tj_free_data_dir_path = os.path.join(base_data_path, \"TjFree\")\n",
    "# error_files  = []\n",
    "# total_tj_free_files = 0\n",
    "# total_tj_detected_in_tj_free_files = 0\n",
    "# for folder in os.listdir(tj_free_data_dir_path):\n",
    "#     # check if folder is a directory\n",
    "#     if not os.path.isdir(os.path.join(tj_free_data_dir_path, folder)):\n",
    "#         continue\n",
    "\n",
    "#     print(f\"Processing TJFree {folder}  ....\")\n",
    "\n",
    "#     raw_dataset_path = Path(os.path.join(tj_free_data_dir_path, folder))\n",
    "#     # raw_dataset_path = Path('../../S-seriesprocessed/S-series/TjFree/s15850-T100')\n",
    "\n",
    "#     # raw_dataset_path = Path('../../VerilogTest')\n",
    "\n",
    "#     data_pkl_path = Path(f'temp_{folder}.pkl')\n",
    "#     # data_pkl_path = Path('data_pkl_path.pkl')\n",
    "\n",
    "#     graph_type = 'DFG'\n",
    "#     device = 'cuda'\n",
    "\n",
    "#     with open(yaml_path, 'r') as f:\n",
    "#         config_dict = yaml.safe_load(f)\n",
    "\n",
    "#     # Update config_dict with additional parameters\n",
    "#     config_dict.update({\n",
    "#         'raw_dataset_path': str(raw_dataset_path),\n",
    "#         'data_pkl_path': str(data_pkl_path),\n",
    "#         'graph_type': graph_type,\n",
    "#         'device': device\n",
    "#     })\n",
    "\n",
    "#     # Initialize the configuration class\n",
    "#     config = Config(config_dict)\n",
    "\n",
    "#     # verilog_file_path = Path('../assets/testing')\n",
    "\n",
    "#     # verilog_file_path = Path('../../AES-T100/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../RS232-T100/src/')\n",
    "#     # verilog_file_path = Path('../../PIC16F84-T200/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../b15-T100/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../s15850-T100/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../ISCAS85/test2')\n",
    "\n",
    "#     verilog_file_path = raw_dataset_path\n",
    "#     # verilog_file_path = Path('../../S-seriesprocessed/S-series/TjFree/s15850-T100')\n",
    "\n",
    "\n",
    "#     # verilog_file_path = Path('../../VerilogTest')\n",
    "\n",
    "#     nx_graphs = []\n",
    "#     hw2graph = HW2GRAPH(config)\n",
    "#     data_proc = DataProcessor(config)\n",
    "\n",
    "#     if data_pkl_path.exists():\n",
    "#         data_proc.read_graph_data_from_cache(data_pkl_path)\n",
    "#         print(\"using cache\")\n",
    "#     else:\n",
    "#         # Process the single Verilog file\n",
    "#         try:\n",
    "#             hw_graph = hw2graph.code2graph(verilog_file_path)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in processing {folder}. \\n Error:  {e}\")\n",
    "#             error_files.append({\n",
    "#                 \"name\": folder,\n",
    "#                 \"error\": e\n",
    "#             })\n",
    "#             continue\n",
    "#         nx_graphs.append(hw_graph)\n",
    "\n",
    "#         for hw_graph in nx_graphs:\n",
    "#             data_proc.process(hw_graph)\n",
    "#         data_proc.cache_graph_data(config.data_pkl_path)\n",
    "#     data=data_proc.get_graphs()\n",
    "\n",
    "#     model_path = \"hw2vec/assets/pretrained_DFG_TJ_RTL/model.pth\"\n",
    "#     config_path = \"hw2vec/assets/pretrained_DFG_TJ_RTL/model.cfg\"\n",
    "\n",
    "\n",
    "#     model = GRAPH2VEC(config)\n",
    "#     model_path = Path(model_path)\n",
    "#     if model_path.exists():\n",
    "#         model.load_model(config_path, model_path)\n",
    "#     else:\n",
    "#         raise Exception(\"Model Does not exist\")\n",
    "\n",
    "#     model.to(config.device)\n",
    "\n",
    "#     def inference(model, data_loader, config):\n",
    "#         with torch.no_grad():\n",
    "#             model.eval()\n",
    "#             for i, data in enumerate(data_loader):\n",
    "#                 data = data.to(config.device)  # Move data to the correct device\n",
    "\n",
    "#                 output, attn = model.embed_graph(data.x, data.edge_index, data.batch)\n",
    "#                 output = model.mlp(output)\n",
    "#                 output = F.log_softmax(output, dim=1)\n",
    "#                 # print(output)\n",
    "\n",
    "\n",
    "\n",
    "#             # outputs = torch.cat(output).reshape(-1, 2).detach()\n",
    "\n",
    "\n",
    "\n",
    "#             # labels_tensor = torch.LongTensor(labels).detach()\n",
    "#             outputs_tensor = torch.FloatTensor(output.cpu()).detach()\n",
    "#             preds = outputs_tensor.max(1)[1].detach()\n",
    "\n",
    "#         return outputs_tensor, preds\n",
    "\n",
    "#     train_loader = DataLoader(data, shuffle=True, batch_size=1)\n",
    "\n",
    "#     outputs_tensor, preds=inference(model, train_loader, config)\n",
    "\n",
    "#     # print(f\"The output tensor is: {outputs_tensor}\")\n",
    "\n",
    "#     trojan_detected = preds[0] == 1\n",
    "#     print(f\"The predicted class is: {'TJ Free' if preds[0] == 0 else 'TJ Detected'}\")\n",
    "\n",
    "#     total_tj_free_files += 1\n",
    "#     if trojan_detected:\n",
    "#         total_tj_detected_in_tj_free_files += 1\n",
    "\n",
    "# print(error_files)\n",
    "\n",
    "# # Now we will process the files with trojans\n",
    "# tj_data_dir_path = os.path.join(base_data_path, \"TjIn\")\n",
    "# # tj_data_dir_path = Path('../../S-seriesprocessed/S-series/TjIn')\n",
    "# # tj_data_dir_path = Path('../assets/datasets/TJ-RTL-tsoy/TjIn')\n",
    "\n",
    "# error_files = []\n",
    "\n",
    "# total_tj_files = 0\n",
    "# total_tj_detected_in_tj_files = 0\n",
    "# for folder in os.listdir(tj_data_dir_path):\n",
    "#     # check if folder is a directory\n",
    "#     if not os.path.isdir(os.path.join(tj_data_dir_path, folder)):\n",
    "#         print(\"skipping file...\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"Processing TJIn {folder}  ....\")\n",
    "\n",
    "\n",
    "#     raw_dataset_path = Path(os.path.join(tj_data_dir_path, folder))\n",
    "#     # raw_dataset_path = Path('../../S-seriesprocessed/S-series/TjFree/s15850-T100')\n",
    "\n",
    "#     # raw_dataset_path = Path('../../VerilogTest')\n",
    "\n",
    "#     data_pkl_path = Path(f'temp_{folder}.pkl')\n",
    "#     graph_type = 'DFG'\n",
    "#     device = 'cuda'\n",
    "\n",
    "#     with open(yaml_path, 'r') as f:\n",
    "#         config_dict = yaml.safe_load(f)\n",
    "\n",
    "#     # Update config_dict with additional parameters\n",
    "#     config_dict.update({\n",
    "#         'raw_dataset_path': str(raw_dataset_path),\n",
    "#         'data_pkl_path': str(data_pkl_path),\n",
    "#         'graph_type': graph_type,\n",
    "#         'device': device\n",
    "#     })\n",
    "\n",
    "#     # Initialize the configuration class\n",
    "#     config = Config(config_dict)\n",
    "\n",
    "#     # verilog_file_path = Path('../assets/testing')\n",
    "\n",
    "#     # verilog_file_path = Path('../../AES-T100/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../RS232-T100/src/')\n",
    "#     # verilog_file_path = Path('../../PIC16F84-T200/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../b15-T100/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../s15850-T100/src/TjIn')\n",
    "#     # verilog_file_path = Path('../../ISCAS85/test2')\n",
    "\n",
    "#     verilog_file_path = raw_dataset_path\n",
    "\n",
    "#     # verilog_file_path = Path('../../S-seriesprocessed/S-series/TjFree/s15850-T100')\n",
    "\n",
    "#     # verilog_file_path = Path('../../VerilogTest')\n",
    "\n",
    "#     nx_graphs = []\n",
    "#     hw2graph = HW2GRAPH(config)\n",
    "#     data_proc = DataProcessor(config)\n",
    "\n",
    "#     if data_pkl_path.exists():\n",
    "#         data_proc.read_graph_data_from_cache(data_pkl_path)\n",
    "#         print(\"using cache\")\n",
    "#     else:\n",
    "#         # Process the single Verilog file\n",
    "#         try:\n",
    "#             hw_graph = hw2graph.code2graph(verilog_file_path)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in processing {folder}. \\n Error:  {e}\")\n",
    "#             error_files.append({\n",
    "#                 \"name\": folder,\n",
    "#                 \"error\": e\n",
    "#             })\n",
    "#             continue\n",
    "#         nx_graphs.append(hw_graph)\n",
    "\n",
    "#         for hw_graph in nx_graphs:\n",
    "#             data_proc.process(hw_graph)\n",
    "#         data_proc.cache_graph_data(config.data_pkl_path)\n",
    "#     data=data_proc.get_graphs()\n",
    "\n",
    "   \n",
    "#     model_path = \"hw2vec/assets/pretrained_DFG_TJ_RTL/model.pth\"\n",
    "#     config_path = \"hw2vec/assets/pretrained_DFG_TJ_RTL/model.cfg\"\n",
    "\n",
    "\n",
    "#     model = GRAPH2VEC(config)\n",
    "#     model_path = Path(model_path)\n",
    "#     if model_path.exists():\n",
    "#         model.load_model(config_path, model_path)\n",
    "#     else:\n",
    "#         raise Exception(\"Model Does not exist\")\n",
    "#     model.to(config.device)\n",
    "\n",
    "#     def inference(model, data_loader, config):\n",
    "#         with torch.no_grad():\n",
    "#             model.eval()\n",
    "#             for i, data in enumerate(data_loader):\n",
    "#                 data = data.to(config.device)  # Move data to the correct device\n",
    "\n",
    "#                 output, attn = model.embed_graph(data.x, data.edge_index, data.batch)\n",
    "#                 output = model.mlp(output)\n",
    "#                 output = F.log_softmax(output, dim=1)\n",
    "#                 # print(output)\n",
    "\n",
    "\n",
    "\n",
    "#             # outputs = torch.cat(output).reshape(-1, 2).detach()\n",
    "\n",
    "\n",
    "\n",
    "#             # labels_tensor = torch.LongTensor(labels).detach()\n",
    "#             outputs_tensor = torch.FloatTensor(output.cpu()).detach()\n",
    "#             preds = outputs_tensor.max(1)[1].detach()\n",
    "\n",
    "#         return outputs_tensor, preds\n",
    "\n",
    "#     train_loader = DataLoader(data, shuffle=True, batch_size=1)\n",
    "\n",
    "#     outputs_tensor, preds=inference(model, train_loader, config)\n",
    "\n",
    "#     # print(f\"The output tensor is: {outputs_tensor}\")\n",
    "\n",
    "#     trojan_detected = preds[0] == 1\n",
    "#     print(f\"The predicted class is: {'TJ Free' if preds[0] == 0 else 'TJ Detected'}\")\n",
    "\n",
    "#     total_tj_files += 1\n",
    "#     if trojan_detected:\n",
    "#         total_tj_detected_in_tj_files += 1\n",
    "# print(error_files)\n",
    "\n",
    "# # compute the accuracy and confusion matrix\n",
    "# #\n",
    "\n",
    "# print(f\"Total TJ Free files: {total_tj_free_files}\")\n",
    "# print(f\"Total TJ Detected in TJ Free files (False Positives): {total_tj_detected_in_tj_free_files}\")\n",
    "# print(f\"Total TJ Free accuracy: {(total_tj_free_files - total_tj_detected_in_tj_free_files) / total_tj_free_files}\")\n",
    "\n",
    "# print(f\"Total TJ files: {total_tj_files}\")\n",
    "# print(f\"Total TJ Detected in TJ files (True Positives): {total_tj_detected_in_tj_files}\")\n",
    "# print(f\"Total TJ accuracy: {total_tj_detected_in_tj_files / total_tj_files}\")\n",
    "\n",
    "# # confusion matrix\n",
    "\n",
    "# # True Positives\n",
    "# # False Positives\n",
    "# # True Negatives\n",
    "# # False Negatives\n",
    "\n",
    "# # Confusion matrix components\n",
    "# TP = total_tj_detected_in_tj_files      # True Positive: correctly detected trojan-inserted\n",
    "# FP = total_tj_detected_in_tj_free_files # False Positive: wrongly detected trojan in trojan-free\n",
    "# FN = total_tj_files - TP                # False Negative: missed detection of trojan\n",
    "# TN = total_tj_free_files - FP           # True Negative: correctly identified trojan-free\n",
    "\n",
    "# # Print metrics\n",
    "# print(f\"True Positives (TjIn correctly detected): {TP}\")\n",
    "# print(f\"False Positives (TjFree wrongly flagged): {FP}\")\n",
    "# print(f\"True Negatives (TjFree correctly identified): {TN}\")\n",
    "# print(f\"False Negatives (TjIn missed): {FN}\")\n",
    "\n",
    "# # Evaluation metrics\n",
    "# eps = 1e-8  # To avoid division by zero\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "# Precision = TP / (TP + FP + eps)\n",
    "# Recall = TP / (TP + FN + eps)\n",
    "# F1 = 2 * (Precision * Recall) / (Precision + Recall + eps)\n",
    "\n",
    "# print(f\"Accuracy: {Accuracy:.4f}\")\n",
    "# print(f\"Precision: {Precision:.4f}\")\n",
    "# print(f\"Recall: {Recall:.4f}\")\n",
    "# print(f\"F1 Score: {F1:.4f}\")\n",
    "\n",
    "# # Create confusion matrix as a DataFrame\n",
    "# # Index = Ground Truth, Columns = Predicted\n",
    "# conf_matrix = {\n",
    "#     'TjFree': [TN, FP],  # Predicted as TjFree or TjIn\n",
    "#     'TjIn': [FN, TP]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(conf_matrix, index=['TjFree', 'TjIn'])  # Ground Truth: TjFree (negative), TjIn (positive)\n",
    "\n",
    "# # Plotting\n",
    "# sns.heatmap(\n",
    "#     df,\n",
    "#     annot=True,\n",
    "#     fmt='d',\n",
    "#     cmap='Blues',\n",
    "#     xticklabels=['Pred: TjFree (Negative)', 'Pred: TjIn (Positive)'],\n",
    "#     yticklabels=['GT: TjFree (Negative)', 'GT: TjIn (Positive)']\n",
    "# )\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('Ground Truth Label')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
